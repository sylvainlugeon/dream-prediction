epoch training validation
0 [7.9341, 19.5190] [3.2417, 9.4426]
1 [7.4410, 20.1056] [3.6312, 9.2725]
2 [6.4839, 19.9975] [3.3707, 9.1727]
3 [6.9279, 19.5802] [3.5278, 9.1010]
4 [6.5652, 19.5509] [3.6660, 9.0167]
5 [6.2407, 19.9330] [3.2734, 8.8787]
6 [6.1106, 19.2285] [3.1604, 8.6752]
7 [5.7618, 18.6982] [2.8822, 8.7049]
8 [5.9293, 19.3292] [2.9024, 8.5959]
9 [5.7066, 18.5928] [3.1201, 8.5027]
10 [5.2392, 18.5578] [3.1440, 8.3438]
11 [5.6722, 18.8024] [3.1945, 8.2986]
12 [5.3127, 18.7329] [3.2468, 8.2073]
13 [5.7531, 18.1310] [3.2612, 8.1562]
14 [5.7515, 18.3721] [2.9762, 8.0176]
15 [5.0608, 17.6715] [3.0754, 7.8839]
16 [5.4215, 17.4479] [3.0119, 7.7509]
17 [4.9269, 17.7000] [2.9681, 7.6999]
18 [4.8831, 18.0986] [2.7152, 7.7035]
19 [5.1413, 17.7884] [2.6777, 7.5989]
20 [4.8122, 17.7109] [2.5571, 7.5773]
21 [4.9144, 17.7398] [2.7057, 7.4577]
22 [4.7609, 17.2002] [3.0679, 7.4144]
23 [5.0527, 17.3957] [2.4986, 7.3392]
24 [4.9551, 17.1028] [3.0046, 7.3417]
25 [4.8251, 17.2897] [2.6590, 7.2700]
26 [4.7751, 17.4411] [2.9183, 7.2389]
27 [4.8563, 17.0002] [2.6462, 7.1540]
28 [4.5947, 16.9271] [2.6840, 6.9869]
29 [4.6550, 16.6117] [3.1614, 6.9670]
30 [4.4548, 17.2490] [2.6990, 6.9982]
31 [4.3695, 16.9250] [2.7393, 7.0352]
32 [4.0405, 16.7875] [2.6984, 6.9435]
33 [4.3175, 16.1484] [2.7809, 6.9023]
34 [4.5333, 16.3969] [2.7848, 6.7887]
35 [4.3235, 16.5155] [2.7433, 6.7810]
36 [4.4870, 16.1969] [2.6863, 6.7818]
37 [4.4168, 16.7232] [2.6527, 6.7760]
38 [4.5182, 16.6899] [2.5973, 6.7692]
39 [4.3300, 16.1096] [2.5936, 6.7647]
