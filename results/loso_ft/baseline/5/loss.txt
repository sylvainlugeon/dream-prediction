epoch training validation
0 [9.0062, 19.8291] [3.7983, 9.4201]
1 [8.3195, 19.7930] [3.0564, 9.2699]
2 [7.7822, 19.3223] [3.2473, 9.0818]
3 [7.5242, 19.5061] [3.0336, 8.8895]
4 [7.4761, 19.3461] [2.8461, 8.8095]
5 [7.6481, 18.8956] [2.9750, 8.6527]
6 [7.2125, 18.8245] [2.8057, 8.5147]
7 [6.9752, 19.3522] [2.7460, 8.3824]
8 [6.6730, 18.9582] [2.7390, 8.3173]
9 [7.0821, 19.3898] [2.4703, 8.2471]
10 [6.5875, 19.0793] [2.7655, 8.0568]
11 [6.3178, 18.2004] [2.3394, 7.8952]
12 [6.5172, 18.2190] [2.3720, 7.7354]
13 [6.1653, 18.1399] [2.2173, 7.7170]
14 [6.4340, 17.9028] [2.3198, 7.6211]
15 [6.4678, 17.9239] [2.2435, 7.4037]
16 [6.1139, 17.6980] [2.1947, 7.3330]
17 [6.2407, 17.8063] [2.2845, 7.2779]
18 [6.0851, 17.8262] [2.0671, 7.2554]
19 [6.5511, 17.3902] [1.8734, 7.1732]
20 [6.0752, 17.8063] [1.8127, 7.2144]
21 [5.8565, 17.3727] [1.9598, 7.1807]
22 [5.5548, 17.2966] [1.8603, 7.1034]
23 [5.5987, 17.2411] [1.7449, 7.0352]
24 [5.3123, 17.4724] [1.8795, 6.9903]
25 [5.5030, 17.4774] [1.7246, 6.8821]
26 [5.6034, 17.3072] [1.7653, 6.7502]
27 [5.6624, 17.3261] [1.7524, 6.6876]
28 [5.5437, 17.1453] [1.7311, 6.5682]
29 [5.0574, 16.7389] [1.7884, 6.4610]
30 [5.4326, 17.0572] [1.7891, 6.3280]
31 [5.3114, 16.6921] [1.7256, 6.3080]
32 [5.2447, 16.4351] [1.6510, 6.2919]
33 [5.2833, 16.1024] [1.6228, 6.2460]
34 [5.0657, 16.3367] [1.6715, 6.2330]
35 [4.9884, 16.2591] [1.6705, 6.2592]
36 [5.1521, 16.0426] [1.7051, 6.2089]
37 [4.6270, 15.5008] [1.6331, 6.1764]
38 [4.6406, 15.6760] [1.7533, 6.1818]
39 [4.6489, 15.9051] [1.6632, 6.1341]
