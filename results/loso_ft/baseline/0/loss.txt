epoch training validation
0 [9.7101, 20.5964] [4.8951, 8.4022]
1 [7.9969, 21.2229] [3.6972, 8.0884]
2 [6.8255, 20.7585] [3.6795, 8.0241]
3 [7.0048, 20.6252] [3.7552, 7.8495]
4 [6.8644, 19.7172] [3.4124, 7.7077]
5 [6.7399, 20.5474] [3.5957, 7.6406]
6 [6.2072, 20.0287] [3.4094, 7.5675]
7 [6.5843, 19.6780] [3.5162, 7.4360]
8 [6.0797, 19.4687] [3.0750, 7.3600]
9 [5.7915, 19.9340] [2.9883, 7.3220]
10 [5.9054, 19.2683] [3.1614, 7.2362]
11 [5.7374, 19.4850] [2.6996, 7.2192]
12 [5.5837, 19.3561] [2.7830, 7.2122]
13 [5.7013, 18.9206] [2.8606, 7.1676]
14 [5.9427, 18.2241] [2.6090, 7.1083]
15 [5.6021, 19.0958] [2.7038, 7.0834]
16 [5.5994, 18.2228] [2.8308, 7.0492]
17 [5.6474, 18.4886] [2.6291, 6.9196]
18 [4.9933, 18.9067] [2.4925, 6.8199]
19 [5.0789, 19.2487] [2.4409, 6.7681]
20 [5.2158, 18.4713] [2.4418, 6.6931]
21 [5.0176, 18.0043] [2.5152, 6.6365]
22 [4.7723, 18.3829] [2.2006, 6.5761]
23 [5.1388, 17.7212] [2.2933, 6.5202]
24 [4.9178, 17.6800] [2.3795, 6.4879]
25 [4.9677, 17.9895] [2.2315, 6.4934]
26 [4.7651, 17.5706] [2.1773, 6.4519]
27 [5.0305, 17.8038] [2.2405, 6.3910]
28 [4.7102, 18.2661] [2.3163, 6.3032]
29 [4.5502, 17.8478] [2.2045, 6.2401]
30 [4.2649, 17.5003] [2.2660, 6.1682]
31 [4.2830, 17.2974] [2.0877, 6.1495]
32 [4.3995, 17.2521] [2.1093, 6.0920]
33 [4.2917, 17.1221] [2.0623, 6.0627]
34 [4.1568, 17.2054] [2.0970, 6.0639]
35 [4.3621, 17.0606] [2.1629, 6.0496]
36 [4.0171, 16.9285] [2.0112, 6.0078]
37 [4.2728, 17.4949] [2.1027, 5.9584]
38 [4.2859, 17.1216] [2.0130, 5.8478]
39 [4.2239, 16.4650] [2.0470, 5.8077]
