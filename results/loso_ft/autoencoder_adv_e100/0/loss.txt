epoch training validation
0 [1.2733,3.3252] [0.7458,1.9847]
1 [1.1772,3.3258] [0.6738,1.9807]
2 [1.0876,3.3027] [0.6300,1.9771]
3 [1.0428,3.2315] [0.6273,1.9695]
4 [1.0448,3.2480] [0.5995,1.9806]
5 [0.9504,3.1690] [0.5815,1.9942]
6 [0.9197,3.0676] [0.5715,2.0036]
7 [0.8870,3.1316] [0.5666,1.9983]
8 [0.8315,3.1329] [0.5514,2.0007]
9 [0.8501,2.9274] [0.5517,1.9950]
10 [0.7658,3.0116] [0.5501,1.9820]
11 [0.7733,2.9279] [0.5321,1.9825]
12 [0.7375,2.8879] [0.5304,1.9725]
13 [0.7154,2.8139] [0.5268,1.9875]
14 [0.7162,2.8788] [0.5099,1.9857]
15 [0.6543,2.8661] [0.5026,1.9845]
16 [0.6288,2.7908] [0.4884,1.9799]
17 [0.5944,2.7963] [0.4804,1.9869]
18 [0.5994,2.7904] [0.4743,1.9875]
19 [0.5752,2.7478] [0.4652,1.9726]
20 [0.5678,2.7693] [0.4575,1.9553]
21 [0.5508,2.7389] [0.4521,1.9533]
22 [0.5150,2.7098] [0.4467,1.9615]
23 [0.4715,2.6978] [0.4427,1.9586]
24 [0.4812,2.7827] [0.4491,1.9585]
25 [0.4612,2.7265] [0.4461,1.9606]
26 [0.4309,2.7607] [0.4457,1.9584]
27 [0.4493,2.6712] [0.4485,1.9455]
28 [0.4217,2.7972] [0.4265,1.9487]
29 [0.3817,2.7253] [0.4438,1.9458]
30 [0.3787,2.7476] [0.4498,1.9509]
31 [0.3573,2.7139] [0.4517,1.9499]
32 [0.3423,2.6688] [0.4809,1.9601]
33 [0.3365,2.6741] [0.4761,1.9491]
34 [0.3120,2.7206] [0.4290,1.9535]
35 [0.3005,2.6192] [0.4190,1.9652]
36 [0.2908,2.7280] [0.4877,1.9759]
37 [0.2737,2.6633] [0.4762,1.9694]
38 [0.2559,2.7206] [0.5196,1.9594]
39 [0.2253,2.7819] [0.5262,1.9689]
40 [0.2211,2.8321] [0.4726,1.9697]
41 [0.2018,2.7607] [0.5256,1.9736]
42 [0.1844,2.7646] [0.6215,1.9731]
43 [0.1887,2.7979] [0.4772,1.9676]
44 [0.1658,2.8199] [0.6279,2.0015]
45 [0.1610,2.8287] [0.6237,2.0164]
46 [0.1474,2.8195] [0.6334,2.0201]
47 [0.1311,2.7958] [0.4788,1.9902]
48 [0.1465,2.9010] [0.4806,1.9907]
49 [0.1410,2.8456] [0.4817,1.9880]
50 [0.1207,2.9172] [0.4997,1.9977]
51 [0.1334,2.8962] [0.4862,1.9893]
52 [0.1260,2.9455] [0.4880,1.9927]
53 [0.1289,2.9297] [0.4885,1.9911]
54 [0.1291,2.8982] [0.4889,1.9931]
