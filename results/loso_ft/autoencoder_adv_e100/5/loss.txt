epoch training validation
0 [1.3913,3.4816] [0.7198,2.0632]
1 [1.3051,3.5204] [0.6750,2.0301]
2 [1.1888,3.3624] [0.6528,1.9648]
3 [1.1517,3.3395] [0.6492,1.9402]
4 [1.1046,3.2701] [0.6171,1.9252]
5 [1.0249,3.1116] [0.5939,1.9029]
6 [0.9730,3.2226] [0.5902,1.9010]
7 [0.9453,3.1147] [0.5712,1.8952]
8 [0.8609,3.0342] [0.5641,1.8824]
9 [0.8193,3.0528] [0.5545,1.8850]
10 [0.7831,3.0105] [0.5409,1.8744]
11 [0.7221,2.9650] [0.5302,1.8664]
12 [0.7000,2.8583] [0.5230,1.8669]
13 [0.6873,2.9197] [0.5177,1.8654]
14 [0.6438,2.9492] [0.5403,1.8771]
15 [0.6026,2.8371] [0.5245,1.8662]
16 [0.6105,2.9231] [0.5488,1.8700]
17 [0.5548,2.8077] [0.5231,1.8703]
18 [0.5541,2.8789] [0.5413,1.8585]
19 [0.5584,2.8077] [0.5452,1.8572]
20 [0.5113,2.8264] [0.5254,1.8547]
21 [0.4985,2.7915] [0.5304,1.8623]
22 [0.5075,2.8009] [0.4929,1.8630]
23 [0.4714,2.8105] [0.5257,1.8680]
24 [0.4503,2.7829] [0.5159,1.8690]
25 [0.4479,2.7661] [0.5085,1.8660]
26 [0.4139,2.8218] [0.5433,1.8628]
27 [0.4025,2.8025] [0.5019,1.8594]
28 [0.3855,2.7226] [0.5477,1.8677]
29 [0.3585,2.6825] [0.5538,1.8731]
30 [0.3528,2.8536] [0.5513,1.8754]
31 [0.3411,2.7288] [0.5201,1.8711]
32 [0.3463,2.7868] [0.5545,1.8625]
33 [0.3172,2.7462] [0.5359,1.8609]
34 [0.2992,2.7252] [0.5603,1.8614]
35 [0.2836,2.6796] [0.5741,1.8608]
36 [0.2897,2.8086] [0.5672,1.8606]
37 [0.3072,2.7889] [0.5512,1.8609]
38 [0.2836,2.7370] [0.5664,1.8608]
39 [0.2861,2.7961] [0.5582,1.8615]
40 [0.3037,2.8282] [0.5893,1.8614]
41 [0.2872,2.8616] [0.5864,1.8618]
