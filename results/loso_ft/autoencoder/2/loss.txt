epoch training validation
0 [1.1157, 3.2486] [0.7355, 2.6127]
1 [1.0141, 3.1037] [0.6519, 2.3988]
2 [0.9055, 2.9226] [0.6285, 2.2371]
3 [0.9077, 2.7813] [0.6217, 2.1073]
4 [0.7732, 2.7339] [0.6072, 2.0149]
5 [0.7681, 2.6082] [0.5890, 1.9473]
6 [0.7424, 2.4936] [0.5753, 1.8973]
7 [0.7122, 2.4706] [0.5584, 1.8536]
8 [0.6585, 2.4267] [0.5540, 1.8314]
9 [0.6261, 2.3762] [0.5263, 1.8042]
10 [0.6364, 2.3240] [0.5052, 1.7863]
11 [0.5534, 2.3733] [0.4838, 1.7691]
12 [0.5536, 2.3044] [0.4713, 1.7598]
13 [0.5168, 2.2843] [0.4560, 1.7501]
14 [0.5005, 2.2439] [0.4243, 1.7355]
15 [0.4840, 2.2304] [0.4410, 1.7266]
16 [0.4476, 2.1620] [0.4197, 1.7163]
17 [0.4455, 2.1789] [0.4059, 1.7018]
18 [0.4296, 2.1517] [0.3905, 1.6872]
19 [0.4086, 2.1409] [0.4203, 1.6776]
20 [0.3665, 2.0931] [0.3816, 1.6655]
21 [0.3585, 2.0644] [0.4281, 1.6597]
22 [0.3463, 2.0773] [0.3799, 1.6493]
23 [0.3146, 2.0608] [0.3815, 1.6396]
24 [0.3071, 2.0343] [0.3811, 1.6280]
25 [0.2684, 2.0311] [0.3802, 1.6198]
26 [0.2685, 1.9993] [0.4064, 1.6077]
27 [0.2586, 1.9871] [0.3772, 1.6016]
28 [0.2378, 1.9863] [0.4204, 1.5861]
29 [0.2151, 1.9466] [0.4573, 1.5796]
30 [0.2150, 1.9569] [0.4938, 1.5685]
31 [0.1940, 1.9311] [0.4263, 1.5658]
32 [0.1922, 1.9350] [0.4841, 1.5575]
33 [0.1748, 1.9096] [0.4820, 1.5509]
34 [0.1629, 1.9474] [0.5408, 1.5525]
35 [0.1535, 1.9428] [0.5250, 1.5435]
36 [0.1372, 1.8993] [0.5649, 1.5345]
37 [0.1354, 1.8772] [0.5040, 1.5348]
38 [0.1112, 1.8955] [0.4792, 1.5499]
39 [0.1001, 1.9129] [0.5088, 1.5438]
