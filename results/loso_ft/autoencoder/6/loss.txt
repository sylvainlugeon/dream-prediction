epoch training validation
0 [1.2078, 2.7433] [0.9661, 1.9995]
1 [1.0145, 2.6759] [0.6217, 1.9258]
2 [0.9434, 2.6781] [0.6024, 1.8846]
3 [0.8804, 2.5147] [0.5956, 1.8504]
4 [0.8567, 2.4796] [0.5928, 1.8228]
5 [0.8195, 2.4664] [0.5807, 1.8101]
6 [0.7928, 2.4489] [0.5797, 1.8009]
7 [0.7649, 2.4032] [0.5727, 1.7927]
8 [0.7318, 2.3706] [0.5682, 1.7852]
9 [0.7612, 2.3439] [0.5712, 1.7800]
10 [0.7023, 2.3085] [0.5594, 1.7747]
11 [0.6739, 2.2368] [0.5548, 1.7676]
12 [0.6590, 2.2716] [0.5473, 1.7612]
13 [0.6492, 2.2489] [0.5433, 1.7574]
14 [0.6409, 2.1988] [0.5359, 1.7546]
15 [0.6072, 2.2102] [0.5274, 1.7531]
16 [0.6205, 2.1959] [0.5237, 1.7513]
17 [0.6107, 2.1835] [0.5153, 1.7472]
18 [0.5890, 2.1308] [0.5085, 1.7447]
19 [0.5642, 2.1434] [0.4970, 1.7421]
20 [0.5613, 2.1255] [0.4918, 1.7420]
21 [0.5307, 2.1361] [0.4903, 1.7382]
22 [0.5274, 2.0806] [0.4857, 1.7353]
23 [0.5083, 2.1390] [0.4732, 1.7322]
24 [0.4974, 2.0916] [0.4792, 1.7282]
25 [0.4843, 2.0873] [0.4758, 1.7293]
26 [0.4496, 2.0859] [0.4669, 1.7274]
27 [0.4407, 2.0650] [0.4669, 1.7242]
28 [0.4070, 2.0634] [0.4628, 1.7235]
29 [0.3929, 2.0580] [0.4464, 1.7218]
30 [0.3815, 2.0445] [0.4602, 1.7120]
31 [0.3399, 2.0102] [0.4784, 1.7089]
32 [0.3275, 2.0038] [0.4642, 1.7057]
33 [0.2888, 1.9899] [0.4852, 1.7010]
34 [0.2667, 2.0381] [0.5521, 1.6957]
35 [0.2433, 2.0090] [0.5184, 1.6857]
36 [0.2261, 2.0106] [0.5401, 1.6802]
37 [0.2030, 1.9850] [0.6181, 1.6793]
38 [0.2052, 2.0010] [0.7054, 1.6747]
39 [0.1747, 2.0255] [0.6525, 1.6654]
