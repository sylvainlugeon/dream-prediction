epoch training validation
0 [1.1650, 3.6749] [0.7213, 3.0834]
1 [1.0864, 3.6493] [0.6407, 2.8705]
2 [0.9596, 3.4013] [0.6283, 2.6756]
3 [0.8966, 3.2323] [0.6212, 2.5082]
4 [0.8426, 3.0867] [0.6092, 2.3841]
5 [0.7748, 2.9638] [0.5940, 2.3163]
6 [0.7788, 2.9223] [0.5849, 2.2597]
7 [0.7579, 2.7936] [0.5527, 2.1942]
8 [0.6763, 2.7099] [0.5340, 2.1543]
9 [0.6437, 2.6779] [0.5188, 2.1142]
10 [0.6272, 2.5792] [0.5277, 2.0667]
11 [0.5939, 2.5265] [0.5099, 2.0098]
12 [0.5650, 2.4698] [0.5123, 1.9718]
13 [0.5229, 2.4686] [0.5065, 1.9516]
14 [0.5373, 2.4280] [0.4849, 1.9189]
15 [0.5186, 2.3480] [0.4857, 1.8940]
16 [0.4726, 2.3107] [0.5043, 1.8785]
17 [0.4439, 2.2975] [0.5006, 1.8499]
18 [0.4474, 2.2500] [0.4786, 1.8249]
19 [0.4187, 2.2259] [0.4740, 1.8049]
20 [0.4119, 2.1695] [0.4743, 1.7911]
21 [0.3889, 2.1594] [0.4978, 1.7892]
22 [0.3687, 2.1682] [0.4700, 1.7652]
23 [0.3365, 2.1674] [0.4946, 1.7669]
24 [0.3648, 2.0976] [0.4800, 1.7551]
25 [0.3234, 2.0837] [0.4601, 1.7255]
26 [0.2991, 2.0588] [0.4563, 1.7140]
27 [0.2950, 2.0334] [0.4880, 1.7123]
28 [0.2746, 2.0397] [0.4906, 1.7023]
29 [0.2638, 1.9671] [0.4816, 1.7021]
30 [0.2425, 1.9936] [0.4971, 1.6976]
31 [0.2314, 1.9505] [0.4836, 1.6760]
32 [0.2015, 1.9234] [0.5363, 1.6911]
33 [0.1969, 1.9467] [0.4696, 1.6515]
34 [0.1730, 1.9256] [0.5120, 1.6802]
35 [0.1735, 1.9290] [0.5022, 1.6766]
36 [0.1637, 1.8967] [0.5057, 1.6715]
37 [0.1481, 1.8634] [0.5383, 1.6842]
38 [0.1294, 1.8972] [0.5357, 1.6523]
39 [0.1360, 1.9106] [0.5259, 1.6508]
