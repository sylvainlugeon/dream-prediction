{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mlodata1/lugeon/miniconda3/envs/eeg-dream-conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/mlodata1/lugeon/eeg_project/scripts')\n",
    "from training.representation import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training.representation.models.adverserial.AdverserialAutoencoder"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.AdverserialAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mlodata1/lugeon/miniconda3/envs/eeg-dream-conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AdverserialAutoencoder' from 'training.representation.models.adverserial' (/mlodata1/lugeon/eeg_project/scripts/training/representation/models/adverserial.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/mlodata1/lugeon/eeg_project/draft/draft.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bk8s.iccluster.epfl.ch-95/mlodata1/lugeon/eeg_project/draft/draft.ipynb#ch0000000vscode-remote?line=12'>13</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m/mlodata1/lugeon/eeg_project/scripts\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bk8s.iccluster.epfl.ch-95/mlodata1/lugeon/eeg_project/draft/draft.ipynb#ch0000000vscode-remote?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m EEG_Image_Batch_Dataset\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bk8s.iccluster.epfl.ch-95/mlodata1/lugeon/eeg_project/draft/draft.ipynb#ch0000000vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrepresentation\u001b[39;00m \u001b[39mimport\u001b[39;00m models, losses\n",
      "File \u001b[0;32m/mlodata1/lugeon/eeg_project/scripts/training/representation/models/__init__.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MaskedAutoEncoder\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfine_tuner\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     FineTuner\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madverserial\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     AdverserialAutoencoder\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AdverserialAutoencoder' from 'training.representation.models.adverserial' (/mlodata1/lugeon/eeg_project/scripts/training/representation/models/adverserial.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sys \n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "sys.path.append('/home/lugeon/eeg_project/scripts')\n",
    "sys.path.append('/mlodata1/lugeon/eeg_project/scripts')\n",
    "\n",
    "from training.dataset.datasets import EEG_Image_Batch_Dataset\n",
    "from training.representation import models, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_val(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            change_val(v)\n",
    "        else:\n",
    "            if k == 'weight':\n",
    "                d[k] = v + 1\n",
    "\n",
    "\n",
    "myd = {'r': 2, 'weight': 0, 'r2': {'weight': 10}}\n",
    "change_val(myd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 2, 'weight': 1, 'r2': {'weight': 11}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEG_Image_Batch_Dataset(\n",
    "    hdf5_file='/mlodata1/lugeon/dream_data/processed/madison_20sec/dataset_nrem_binary.h5',\n",
    "    window=10,\n",
    "    slide=5,\n",
    "    shuffle=True,\n",
    "    batch_size=None,\n",
    "    transforms=None,\n",
    "    return_metadata=True,\n",
    "    output_type='label',\n",
    "    next_frame_index=None,\n",
    "    exclude_subject=[0, 1])\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=None, shuffle=False)\n",
    "\n",
    "labels = []\n",
    "subject_ids = []\n",
    "trial_ids = []\n",
    "frame_ids = []\n",
    "sleep_stages = []\n",
    "elapsed_times = []\n",
    "\n",
    "for input_batch, output_batch, metadata in loader:\n",
    "    \n",
    "    sid_batch, tid_batch, fid_batch, ss_batch, et_batch = metadata\n",
    "                        \n",
    "    labels.append(output_batch.cpu().detach().numpy())\n",
    "    subject_ids.append(sid_batch.cpu().detach().numpy())\n",
    "    trial_ids.append(tid_batch.cpu().detach().numpy())\n",
    "    frame_ids.append(fid_batch.cpu().detach().numpy())\n",
    "    sleep_stages.append(ss_batch.cpu().detach().numpy())\n",
    "    elapsed_times.append(et_batch.cpu().detach().numpy())\n",
    "    \n",
    "    del input_batch\n",
    "    del output_batch\n",
    "    del sid_batch\n",
    "    del ss_batch\n",
    "        \n",
    "y = np.concatenate(labels)\n",
    "s = np.concatenate(subject_ids)\n",
    "t = np.concatenate(trial_ids)\n",
    "f = np.concatenate(frame_ids)\n",
    "ss = np.concatenate(sleep_stages)\n",
    "et = np.concatenate(elapsed_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    276\n",
       "3    228\n",
       "4    198\n",
       "5    282\n",
       "6    348\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(s).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H009_E1_NREM_S03.img\n",
      "H009_E1_NREM_S05.img\n",
      "H009_E1_NREM_S06.img\n",
      "H009_E1_NREM_S07.img\n",
      "H009_E1_NREM_S09.img\n",
      "H009_E1_REM_S04.img\n",
      "H009_E1_REM_S08.img\n",
      "H009_E1_REM_S12.img\n",
      "H009_E2_NREM_S01.img\n",
      "H009_E2_NREM_S07.img\n",
      "H009_E2_NREM_S08.img\n",
      "H009_E2_NREM_S09.img\n",
      "H009_E1_NREM_S01.img\n",
      "H009_E1_NREM_S02.img\n"
     ]
    }
   ],
   "source": [
    "with np.load('/mlodata1/lugeon/dream_data/processed/healthy/images/H009.npz') as images:\n",
    "    for k in images:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 5, 32, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with np.load('/home/lugeon/eeg_project/H009.npz') as images:\n",
    "    h018 = images['H009_E1_REM_S12.img']\n",
    "\n",
    "h018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "shw = ax.imshow(h018[3, 4, :, :], cmap='bone', vmin=-2, vmax=2);\n",
    "bar = plt.colorbar(shw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "shw = ax.imshow(h018[0, 1, :, :], cmap='bone', vmin=-2, vmax=2);\n",
    "bar = plt.colorbar(shw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/mlodata1/yuecetue/eeg-dreams/YuceturkThesis2020/Data/hdf5/32_32_FFT_data_all_bands_120s_20sbj_log_z-score_stages23') as f:\n",
    "    for k in f:\n",
    "        print(f[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"frame_id\": shape (46176,), type \"<f4\">\n",
      "<HDF5 dataset \"images\": shape (46176, 5, 32, 32), type \"<f4\">\n",
      "<HDF5 dataset \"labels\": shape (46176,), type \"<f4\">\n",
      "<HDF5 dataset \"sleep_cycle\": shape (46176,), type \"<f4\">\n",
      "<HDF5 dataset \"sleep_stage\": shape (46176,), type \"<f4\">\n",
      "<HDF5 dataset \"subject_id\": shape (46176,), type \"<f4\">\n",
      "<HDF5 dataset \"subject_name\": shape (1,), type \"|S4\">\n",
      "<HDF5 dataset \"trial_id\": shape (46176,), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/mlodata1/lugeon/dream_data/processed/baseline/dataset_bis.h5') as f:\n",
    "    for k in f:\n",
    "        print(f[k])\n",
    "\n",
    "    frame_id = f['frame_id'][:]\n",
    "    subject_id = f['subject_id'][:]\n",
    "    trial_id = f['trial_id'][:]\n",
    "    images = f['images'][:]\n",
    "    labels = f['labels'][:]\n",
    "    sleep_cycle = f['sleep_cycle'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    14814\n",
       "3.0    10614\n",
       "4.0    10494\n",
       "1.0    10254\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sleep_cycle).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/mlodata1/lugeon/dream_data/processed/healthy/dataset_small.h5') as f:\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "                'sid': f['subject_id'][:], \n",
    "                'tid': f['trial_id'][:], \n",
    "                'fid': f['frame_id'][:],\n",
    "                'ss': f['sleep_stage'][:]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#refs#\n",
      "chanlocs\n",
      "condi\n",
      "datavr\n",
      "events\n",
      "numseg\n",
      "ordseg\n",
      "reactime\n",
      "srate\n",
      "stage\n",
      "subject\n"
     ]
    }
   ],
   "source": [
    "file_path = '/mlodata1/lugeon/dream_data/chuv/healthy/H009/H009_E1_NREM_S01.mat'\n",
    "with h5py.File(file_path,'r') as file:\n",
    "        for k in file:\n",
    "                print(k)\n",
    "        time_signal = np.array(file['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0341, 2.0136, 0.0437, 2.0085, 0.0713, 2.0199, 0.0541, 2.0203, 2.0593,\n",
       "        2.0386], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "ft = models.FineTuner(\n",
    "    result_dir='/home/lugeon/eeg_project/results/transformers/masked_auto_encoder_mask9',\n",
    "    encoding_dim=512,\n",
    "    n_classes=2,\n",
    "    dropout=0.8,\n",
    "    adverserial=True,\n",
    "    adv_strength=0.0,\n",
    "    n_adv_classes=7,\n",
    "    freeze=False)\n",
    "\n",
    "optim = torch.optim.Adam(ft.parameters(), lr = 1)\n",
    "out = ft.forward(torch.ones(7, 10, 5, 32, 32))\n",
    "loss = (out[0] - (torch.ones(7, 2) * 1000)).sum()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "\n",
    "w = ft.model.encoder[0][0].fn[0].weight\n",
    "w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dropout(model, new_drop_rate):\n",
    "    for name, child in model.named_children():\n",
    "        if isinstance(child, torch.nn.Dropout):\n",
    "            child.p = new_drop_rate\n",
    "        set_dropout(child, new_drop_rate)\n",
    "        \n",
    "set_dropout(ft, new_drop_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuner(\n",
       "  (model): MaskedAutoEncoder(\n",
       "    (encoder): AttentionNet(\n",
       "      (0): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): AttentionNet(\n",
       "      (0): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.2, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU()\n",
       "              (2): Dropout(p=0.2, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pos_adder): PositionalAdder()\n",
       "    (patch_transform): PatchTransform(\n",
       "      (projection): Conv3d(5, 512, kernel_size=(2, 4, 4), stride=(2, 4, 4))\n",
       "    )\n",
       "    (pixel_transform): PixelTransform(\n",
       "      (projection): Conv2d(1, 160, kernel_size=(1, 512), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (clf): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (adv_clf): Linear(in_features=512, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1 = '/home/lugeon/eeg_project/scripts/training/representation/result/arch_comparison/next_frame_baseline/checkpoint.pt'\n",
    "ch2 = '/home/lugeon/eeg_project/scripts/training/representation/result/evaluate/baseline/0/checkpoint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3087e-05,  2.3708e-03, -3.6374e-03,  ..., -4.2212e-03,\n",
       "         -4.2731e-03,  1.7014e-03],\n",
       "        [ 2.8183e-03,  3.3636e-03,  5.4030e-04,  ...,  3.8198e-03,\n",
       "         -2.3750e-03,  4.1322e-03],\n",
       "        [-1.2480e-03,  3.3899e-03, -3.1663e-03,  ...,  1.5401e-03,\n",
       "          2.5765e-03, -1.7713e-03],\n",
       "        ...,\n",
       "        [-3.4439e-03, -1.7843e-03,  1.3494e-03,  ..., -1.3713e-03,\n",
       "         -9.1726e-04, -5.6303e-04],\n",
       "        [-1.6230e-04,  4.2410e-03, -3.6021e-03,  ..., -2.1716e-03,\n",
       "         -3.3971e-03, -1.1198e-03],\n",
       "        [-2.7684e-03, -2.7571e-03, -3.2507e-03,  ...,  3.0038e-03,\n",
       "          2.3743e-03,  4.2741e-03]], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(ch1)['encoder.1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3087e-05,  2.3708e-03, -3.6374e-03,  ..., -4.2212e-03,\n",
       "         -4.2731e-03,  1.7014e-03],\n",
       "        [ 2.8183e-03,  3.3636e-03,  5.4030e-04,  ...,  3.8198e-03,\n",
       "         -2.3750e-03,  4.1322e-03],\n",
       "        [-1.2480e-03,  3.3899e-03, -3.1663e-03,  ...,  1.5401e-03,\n",
       "          2.5765e-03, -1.7713e-03],\n",
       "        ...,\n",
       "        [-3.4439e-03, -1.7843e-03,  1.3494e-03,  ..., -1.3713e-03,\n",
       "         -9.1726e-04, -5.6303e-04],\n",
       "        [-1.6230e-04,  4.2410e-03, -3.6021e-03,  ..., -2.1716e-03,\n",
       "         -3.3971e-03, -1.1198e-03],\n",
       "        [-2.7684e-03, -2.7571e-03, -3.2507e-03,  ...,  3.0038e-03,\n",
       "          2.3743e-03,  4.2741e-03]], device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(ch2)['model.encoder.1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('eeg-dream-conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0c3161eab2e75dfcb96e4a863b884d85431a87580826b5743bc70e49f36ae89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
